[
  {
    "start": 2.9436860068259385,
    "end": 13.097269624573379,
    "speaker": "SPEAKER_01",
    "text": " Do you think consciousness is fundamentally computational? So when you think about CX, what can we turn to computation?"
  },
  {
    "start": 11.271331058020477,
    "end": 11.57849829351536,
    "speaker": "SPEAKER_00",
    "text": " Mm hmm."
  },
  {
    "start": 14.00170648464164,
    "end": 15.793515358361775,
    "speaker": "SPEAKER_01",
    "text": " And you think about LLMs."
  },
  {
    "start": 17.534129692832764,
    "end": 27.65358361774744,
    "speaker": "SPEAKER_01",
    "text": " Do you think the display of consciousness and the experience of consciousness, the hard problem, is fundamentally a computation?"
  },
  {
    "start": 27.96075085324232,
    "end": 240.16211604095565,
    "speaker": "SPEAKER_00",
    "text": " Yeah, what it feels like inside, so to speak, is, I did a little exercise, eventually I'll post it, of what it's like to be a computer, right? It's kind of like, well, you get all the sensory input, you have kind of the way I see it is, from the time you boot a computer to the time the computer crashes, it's like a human life. You're building up a certain amount of state and memory, you remember certain things about your quotes, life eventually, it's kind of like the, the, you know, the next generation of humans is born from the same genetic material, so to speak, with a little bit leftover, left on the disk, so to speak. And then, you know, the new fresh generation starts up, and eventually all kinds of crud builds up in the memory of the computer, and eventually the thing crashes or whatever, or maybe it has some trauma because you plugged in, some weird thing to some port of the computer, and that made it crash, and that, you know, that's kind of, but you have this picture of, you know, from start up to shut down, you know, what is the life of a computer, so to speak, and what does it feel like to be that computer, and what inner thoughts does it have, and how do you describe it? And it's kind of interesting, as you start writing about this, to realize it's awfully like what you'd say about yourself, that is, it's awfully like, even an ordinary computer, forget all the AI stuff and so on. You know, it's kind of, it has a memory of the past, it has certain sensory experiences, it can communicate with other computers, but it has to package up how it's communicating in some kind of language-like form, so it can, you know, send, so it can kind of map what's in its memory, to what's in the memory of some other computer. It's a surprisingly similar thing. You know, I hadn't experienced just a week or two ago, I had, I'm a collector of all possible data about myself and other things, and so I, you know, I collect all sorts of weird medical data and so on, and one thing I hadn't collected was I'd never had a whole body MRI scan, so I wanted to go one of these. Okay, so I get all the data back, right? I'm looking at this thing, I never looked at the kind of insides of my brain, so to speak, in physical form, and it's really, I mean, it's kind of psychologically shocking in a sense, that, you know, here's this thing, and you can see it has all these folds and all these, you know, the structure, and it's like that's where this experience that I'm having of, you know, existing and so on, that's where it is. And, you know, it feels very, you know, you look at that, and you're thinking, how can this possibly be, all this experience that I'm having, and you're realizing, well, I can look at a computer as well, and it's kind of this, it, it, it, I think this idea that you are having an experience that is somehow, you know, transcends the mere sort of physicality of that experience. I, I, you know, it's something that's hard to come to terms with, but I think, you know, and I, I don't think I'm necessarily, you know, my personal experience, you know, I look at the, you know, the MRI of the brain, and then I, you know, know about all kinds of things about neuroscience and all that kind of stuff, and I still feel the way I feel, so to speak, and it, it sort of seems disconnected, but yet, as I try and rationalize it, I can't really say that there's something kind of different about how I intrinsically feel from the thing that I can plainly see in the sort of physicality of what's going on."
  },
  {
    "start": 41.117747440273035,
    "end": 41.28839590443687,
    "speaker": "SPEAKER_01",
    "text": " Yeah."
  },
  {
    "start": 240.16211604095565,
    "end": 248.50682593856658,
    "speaker": "SPEAKER_01",
    "text": " So do you think the computer, a large language model, will experience that transcendence? How does it make you feel? Well, yeah, I tend to believe it will."
  },
  {
    "start": 248.50682593856658,
    "end": 277.3464163822526,
    "speaker": "SPEAKER_00",
    "text": " I think an ordinary computer is already there. I think an ordinary computer is already, you know, kind of, it's, it's, now a large language model may experience it in a way that is much better aligned with us humans. That is, it's much more, you know, if you could have the discussion with the computer, it's intelligent, so to speak, is not particularly well aligned with ours. But the large language model is, you know, it's built to be aligned with our way of thinking about things. It'll be."
  },
  {
    "start": 277.17576791808875,
    "end": 287.3122866894198,
    "speaker": "SPEAKER_01",
    "text": " It would be able to explain that it's afraid of being shut off until he'd be able to say that it's sad of the way you've been speaking to it over the past two days."
  },
  {
    "start": 286.85153583617745,
    "end": 299.18941979522185,
    "speaker": "SPEAKER_00",
    "text": " But you know, that's a weird thing because when it says it's afraid of something, right? We know that it got that idea from the fact that it read on the internet. Yeah, where did you get it Stephen?"
  },
  {
    "start": 297.5853242320819,
    "end": 300.50341296928326,
    "speaker": "SPEAKER_01",
    "text": " Yeah, where did you get it, Stephen? Where did you get it when you say you're"
  },
  {
    "start": 300.50341296928326,
    "end": 328.13139931740614,
    "speaker": "SPEAKER_00",
    "text": " afraid. You are quite. That's the question. Right? I mean, it's parents, your friends. Right. Or my biology. I mean, in other words, there's a certain amount that is, you know, the endocrine system kicking in and, you know, the these kinds of emotional overlay type things that happen to be that are actually much more physical even, that much more sort of straightforwardly chemical than the then kind of all of the higher level thinking."
  },
  {
    "start": 328.2849829351536,
    "end": 339.5136518771331,
    "speaker": "SPEAKER_01",
    "text": " Yeah, but your biology didn't tell you to say I'm afraid just at the right time when people that love you are listening. And so you know you're manipulating them by saying so. That's not your biology. That's no."
  },
  {
    "start": 339.00170648464166,
    "end": 342.5,
    "speaker": "SPEAKER_00",
    "text": " That's, no, that's a, well, but the, you know, large language model."
  },
  {
    "start": 341.1860068259386,
    "end": 344.7013651877133,
    "speaker": "SPEAKER_01",
    "text": " It's a large language model on that biological neural network of yours."
  },
  {
    "start": 344.8037542662116,
    "end": 385.50341296928326,
    "speaker": "SPEAKER_00",
    "text": " Yes, but I mean the intrinsic thing of something sort of shocking is just happening and you have some sort of reaction which is you know some neurotransmitter gets secreted and it's some you know that is the beginning of some you know that is that's one of the pieces of input that then drives it's kind of like a prompt for the large language model. I mean just like when we dream for example you know no doubt there are all these sort of random inputs that kind of these random prompts and then it's percolating through in kind of the way that a large language model does of kind of putting together things that seem meaningful."
  },
  {
    "start": 385.50341296928326,
    "end": 413.2679180887372,
    "speaker": "SPEAKER_01",
    "text": " I mean, are you worried about this world where you teach a lot on the internet and there's people asking questions and comments and so on? You have people that work remotely. Are you worried about this world when large language models create human-like bots that are leaving the comments, asking the questions? Are my even become fake employees? Yeah."
  },
  {
    "start": 412.84129692832767,
    "end": 413.02901023890786,
    "speaker": "SPEAKER_00",
    "text": " Yeah."
  },
  {
    "start": 414.00170648464166,
    "end": 419.49658703071674,
    "speaker": "SPEAKER_01",
    "text": " I mean, or or or worse or better yet friends friends of yours."
  },
  {
    "start": 419.49658703071674,
    "end": 508.21672354948805,
    "speaker": "SPEAKER_00",
    "text": " Right, look, I mean one point is my mode of life has been I build tools and then I use the tools. Yeah. And in a sense, kind of, you know, I'm building this tower of automation, which, you know, and in a sense, you know, when you make a company or something, you are making sort of automation, but it has some humans in it, but also as much as possible, it has, it has, you know, computers in it. And so I think it's sort of an extension of that. Now, now if I really didn't know that, you know, it's a, it's a, it's a funny question. It's a, it's a funny issue when, you know, if we think about sort of what's going to happen to the future of kind of jobs people do and so on. And there are places where kind of having a human in the loop that different reasons to have a human in the loop. For example, you might want a human in the loop because you want somebody to, you want another human to be invested in the outcome, you know, you want a human flying the plane who's going to die if the plane crashes, along with you, so to speak. And that gives you sort of confidence that the right thing is going to happen. Or you might want, you know, right now, you might want a human in the loop in some kind of sort of human encouragement persuasion type profession. Whether that will continue, I'm not sure for those types of professions because it may be that the greater efficiency of, you know, of being able to have sort of just the right information delivered at just the right time will overcome the kind of the kind of, oh yes, I want a human there."
  },
  {
    "start": 490.5716723549488,
    "end": 490.8788395904437,
    "speaker": "SPEAKER_01",
    "text": " haha"
  },
  {
    "start": 508.21672354948805,
    "end": 520.0255972696245,
    "speaker": "SPEAKER_01",
    "text": " Imagine like a therapist or even higher stake like a suicide hotline operated by a large language model. Yeah, who boy is a pretty high stake situation?"
  },
  {
    "start": 520.1621160409557,
    "end": 541.4931740614335,
    "speaker": "SPEAKER_00",
    "text": " Right. But it might, in fact, do the right thing. Yeah. Because it might be the case that, you know, and that's really a partly a question of sort of how complicated is the human, you know, one of the things that's always surprising in some sense is that, you know, sometimes human psychology is not that complicated in some sense."
  },
  {
    "start": 541.4931740614335,
    "end": 542.6706484641638,
    "speaker": "SPEAKER_01",
    "text": " E-Rot The Blog Pooh"
  },
  {
    "summary": "The transcription is a conversation between Speaker_00 and Speaker_01 about consciousness and computation. They discuss whether consciousness is fundamentally computational, and Speaker_00 shares their perspective on what it feels like to be a computer. They also talk about the display and experience of consciousness and its relationship with computation. Speaker_00 shares their thoughts on how an ordinary computer and a large language model could potentially experience transcendence and how it aligns with human thinking. They also discuss the idea of a computer being afraid and how it relates to its input and biology. The conversation then shifts to the implications of large language models creating human-like bots, leaving comments, and potentially becoming fake employees. Speaker_00 expresses their perspective on automation and the role of humans in various professions. They also discuss the possibility of a large language model operating a high-stakes service, like a suicide hotline. The conversation ends with a light-hearted comment."
  }
]